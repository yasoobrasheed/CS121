# CS121 Linear regression
# General purpose model representation and selection code

import numpy as np
import matplotlib.pylab as plt
import math
from asserts import assert_Xy, assert_Xbeta


#############################
#                           #
#  Our code: DO NOT MODIFY  #
#                           #
#############################


def prepend_ones_column(A):
    """
    Add a ones column to the left side of an array
    """
    ones_col = np.ones((A.shape[0], 1))
    return np.hstack([ones_col, A])


def linear_regression(X, y):
    """
    Compute linear regression. Finds model, beta, that minimizes
    X*beta - y in a least squared sense.

    Inputs:
        X: (2D Numpy array of floats) predictor/independent variables
        y: (1D Numpy array) dependent variable

    Returns: Numpy array beta, which is used only by apply_beta

    Examples
    --------
    >>> X = np.array([[5, 2], [3, 2], [6, 2.1], [7, 3]]) # predictors
    >>> y = np.array([5, 2, 6, 6]) # dependent
    >>> beta = linear_regression(X, y)  # compute the coefficients
    >>> beta
    array([ 1.20104895,  1.41083916, -1.6958042 ])
    >>> apply_beta(beta, X) # apply the function defined by beta
    array([ 4.86363636,  2.04195804,  6.1048951 ,  5.98951049])
    """
    assert_Xy(X, y, fname='linear_regression')

    X_with_ones = prepend_ones_column(X)

    # Do actual computation
    beta = np.linalg.lstsq(X_with_ones, y)[0]

    return beta


def apply_beta(beta, X):
    '''
    Apply beta, the function generated by linear_regression, to the
    specified values

    Inputs:
      beta: beta as returned by linear_regression
      X: (2D Numpy array of floats) predictor/independent variables

    Returns:
      result of applying beta to the data, as an array.

      Given:
        beta = array([B0, B1, B2,...BK])
        X = array([[x11, x12, ..., x0K],
                   [x21, x22, ..., x1K],
                   ...
                   [xN1, xN2, ..., xNK]])

      result will be:
        array([B0+B1*x11+B2*x12+...+BK*x1K,
               B0+B1*x21+B2*x22+...+BK*x2K,
               ...
               B0+B1*xN1+B2*xN2+...+BK*xNK])
    '''
    assert_Xbeta(X, beta, fname='apply_beta')

    # Add a column of ones
    X_incl_ones = prepend_ones_column(X)

    # Calculate X*beta
    yhat = np.dot(X_incl_ones, beta)
    return yhat


###############
#             #
#  Your code  #
#             #
###############


class Model(object):
    '''
    Construct a data structure to hold the model.

    Inputs:
        dataset: a dataset instance
        pred_vars: a list of the indices for the columns used in
        the model.

    Variables:
        t_data: numpy array of dataset training data
        dep_var_index: int index of dependent variable
        labels: list of dataset column labels
        X: 2D numpy array of predictor variables
        y: 1D numpy array of the dependent variable
        testing_data: dataset testing data 
        testing_X: 2D numpy array of predictor variables
        testing_Y: 1D numpy array of dependent variables
    '''
    def __init__(self, dataset, pred_vars):
        self.dataset = dataset
        self.pred_vars = pred_vars

        self.t_data = self.dataset.training_data
        self.dep_var_index = self.dataset.dep_var_index
        self.labels = self.dataset.column_labels

        self.X = self.t_data[:, self.pred_vars]
        self.y = self.t_data[:, self.dep_var_index]

        self.testing_data = self.dataset.testing_data
        self.testing_X = self.testing_data[:, self.pred_vars]
        self.testing_y = self.testing_data[:, self.dep_var_index]


    '''
    Print the beta equation and r2 values for each independent     
    variable in X 

    Variables:
        X: 2D numpy array of predictor variables
        y: 1D numpy array of the dependent variable
        empty: string of beta equation
    '''
    def task_one_a(self):
        for i in self.pred_vars:
            X = self.X[:, i:(i + 1)]
            y = self.y
            beta = linear_regression(X, y)
            y_hat = np.array(apply_beta(beta, X))
            empty = self.labels[self.dep_var_index] + " ~ " + str(beta[0])
            empty += " + " + str(beta[1]) + " * " + self.labels[i]
            print(empty)
            print("R2: " + str(self.compute_r2(y, y_hat)))
    

    '''
    Print the beta equation and r2 value for all independent     
    variables together in X 

    Variables:
        empty: string of beta equation
    '''
    def task_one_b(self):
        beta = linear_regression(self.X, self.y)
        empty = str(self.labels[self.dep_var_index]) + " ~ " + str(beta[0])
        y_hat = np.array(apply_beta(beta, self.X))
        for i in range(0, len(self.pred_vars)):
            empty += " + " + str(beta[i + 1])
            empty += " * " + self.labels[self.pred_vars[i]] 
        print(empty) 
        print("R2: " + str(self.compute_r2(self.y, y_hat)))
        
    
    '''
    Print the beta equation and r2 value for the two independent     
    variables with the highest r2 value in X 

    Variables:
        saved_str: string with the beta equation of the best bivariate
        saved_r2: float with the r2 value of the best bivariate
        X: 2D numpy array of predictor variables
        empty: string of beta equation
    '''
    def task_two(self):
        saved_str = ""
        saved_r2 = 0
        for i in range(0, len(self.pred_vars)):
            for j in range(i + 1, len(self.pred_vars)):
                X = self.X[:, [i, j]]
                beta = linear_regression(X, self.y)
                empty = str(self.labels[self.dep_var_index])
                empty += " ~ " + str(beta[0])
                empty += " + " + str(beta[1]) + " * " + self.labels[i]
                empty += " + " + str(beta[2]) + " * " + self.labels[j]
                y_hat = np.array(apply_beta(beta, X))
                r2 = self.compute_r2(self.y, y_hat)
                if r2 > saved_r2:
                    saved_str = empty
                    saved_r2 = r2
        print(saved_str)
        print("R2: " + str(saved_r2)) 


    '''
    Find the greatest r2 value for the best K-variable model

    Variables:
        pred_list: list of pred_vars
        reverse_list: used to reverse the data
        tup: tuple with the best beta list, r2 value, and list
    '''
    def task_three(self):
        pred_list = self.pred_vars
        reverse_list = []
        while len(pred_list) > 1:
            tup = self.find_n_sub_1(pred_list)
            empty = str(self.labels[self.dep_var_index])
            empty += " ~ " + str(tup[0][0])
            for i in range(0, len(tup[2])):
                empty += " + " + str(tup[0][i + 1]) 
                empty += " * " + self.labels[self.pred_vars[tup[2][i]]] 
            reverse_list.append("R2: " + str(tup[1]))
            reverse_list.append(empty)
            reverse_list.append("")
            pred_list = tup[2]

        for i in reversed(reverse_list):
            print(i)
    

    '''
    Find the best array of n - 1 size from the pred_list 

    Inputs:
        pred_list: list of the predictor array values

    Variables:
        saved_str: string with the beta equation of the best pred_list
        saved_r2: float with the r2 value of the best pred_list
        saved_list: list that equals the best pred_list
        X: 2D numpy array of predictor variables
        empty: string of beta equation

    Return:
        tuple with the best beta, r2 value, and k-value list
    '''
    def find_n_sub_1(self, pred_list):
        saved_list = []
        saved_beta = []
        saved_r2 = 0
        for i in range(0, len(pred_list)):
            first_slice = pred_list[:i]
            second_slice = pred_list[i+1:]
            new_pred_list = first_slice + second_slice
            X = self.X[:, new_pred_list]
            beta = linear_regression(X, self.y)
            y_hat = np.array(apply_beta(beta, X))
            r2 = self.compute_r2(self.y, y_hat)
            if r2 > saved_r2:
                saved_list = new_pred_list
                saved_beta = beta
                saved_r2 = r2
        
        return (saved_beta, saved_r2, saved_list)


    '''
    Print the beta equation, r2 values, and best_k and calculate the adjusted r2

    Variables:
        best_tup_tup: tuple call to find_best_tup()
        best_tup: best tuple from call to find_best_tup()
        best_r2: best float r2 from the data
        best_k: int length of array with best_r2

    Return:
        prints the best beta equation, r2 value, and adjusted_r2_value
    '''
    def task_four(self):
        best_tup_tup = self.find_best_tup()
        best_tup = best_tup_tup[0]
        best_r2 = best_tup_tup[1]
        best_k = best_tup_tup[2]
        
        empty = str(self.labels[self.dep_var_index])
        empty += " ~ " + str(best_tup[0][0])
        for i in range(0, len(best_tup[2])):
            empty += " + " + str(best_tup[0][i + 1])
            empty += " * " + self.labels[self.pred_vars[best_tup[2][i]]] 
        print(empty)
        print("R2: " + str(best_tup[1]))
        print("Adjusted R2: " + str(self.adj_r2(best_r2, best_k, self.y)))
    

    '''
    Find the call to n_sub_1 with the highest beta, r2, and k values

    Variables:
        best_tup: best tuple from call to find_best_tup()
        best_r2: best float r2 from the data
        best_k: int length of array with best_r2

    Return:
        tuple with the best beta tuple, r2 value, and k-value
    '''
    def find_best_tup(self):
        pred_list = self.pred_vars
        best_tup = None
        best_r2 = 0
        best_k = 0
        while len(pred_list) > 1:
            tup = self.find_n_sub_1(pred_list)
            pred_list = tup[2]

            if tup[1] > best_r2:
                best_tup = tup
                best_r2 = tup[1]
                best_k = len(pred_list)

        return (best_tup, best_r2, best_k)
        

    '''
    Print the beta equation, training data r2 values, and testing data r2 values 

    Variables:
        best_tup_tup: tuple call to find_best_tup()
        best_tup: best tuple from call to find_best_tup()
        best_r2: best float r2 from the data
        best_k: int length of array with best_r2
        testing_y_hat: numpy array calculated with the testing_data predictors
        testing_r2: compute the float r2 with the testing_y_hat 

    Return:
        prints the best beta equation, r2 value, and testing_r2_value
    '''
    def task_five(self):
        best_tup_tup = self.find_best_tup()
        best_tup = best_tup_tup[0]
        best_r2 = best_tup_tup[1]
        best_k = best_tup_tup[2]
        
        testing_y_hat = apply_beta(best_tup[0], self.testing_X[:, best_tup[2]])
        testing_r2 = self.compute_r2(self.testing_y, testing_y_hat)
        
        empty = str(self.labels[self.dep_var_index]) 
        empty += " ~ " + str(best_tup[0][0])
        for i in range(0, len(best_tup[2])):
            empty += " + " + str(best_tup[0][i + 1]) 
            empty += " * " + self.labels[self.pred_vars[best_tup[2][i]]] 
        print(empty)
        print("Training R2: " + str(best_tup[1]))
        print("Testing R2: " + str(testing_r2))


    '''
    Calculate the adjusted r2 value

    Inputs:
        r2: float r2 value
        k: int predictor variable value
        y: array dependent variable

    Variables:
        N: integer length of the array of dependent variables

    Return:
        float solving the equation
    '''
    def adj_r2(self, r2, k, y):
        N = len(y)
        return r2 - (1 - r2) * (k / (N - k - 1))


    '''
    Calculate the variance of the dependent variable

    Inputs:
        y: array dependent variable

    Variables:
        N: integer length of the array of dependent variables

    Return:
        float solving the equation
    '''
    def variance(self, y):
        N = len(y)
        return 1 / N * np.sum(y ** 2) 
    

    '''
    Calculate the r2 value

    Inputs:
        y: array dependent variable
        y_hat: array residual variable

    Return:
        float solving the equation
    '''
    def compute_r2(self, y, y_hat):
        return 1 - (self.variance(y - y_hat) / self.variance(y - np.mean(y)))